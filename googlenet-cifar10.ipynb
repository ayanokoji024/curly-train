{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Layer\n",
    "import math\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPool2D,Dropout, Dense, Input, concatenate,GlobalAveragePooling2D, AveragePooling2D,Flatten\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T08:51:54.382197Z",
     "iopub.execute_input": "2023-09-24T08:51:54.382543Z",
     "iopub.status.idle": "2023-09-24T08:51:55.580063Z",
     "shell.execute_reply.started": "2023-09-24T08:51:54.382483Z",
     "shell.execute_reply": "2023-09-24T08:51:55.579359Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": "Using TensorFlow backend.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 32\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-09-24T08:51:55.581432Z",
     "iopub.execute_input": "2023-09-24T08:51:55.581712Z",
     "iopub.status.idle": "2023-09-24T08:51:55.587486Z",
     "shell.execute_reply.started": "2023-09-24T08:51:55.581666Z",
     "shell.execute_reply": "2023-09-24T08:51:55.585313Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_classes = 10\n",
    "def cifar10_data(img_rows, img_cols):\n",
    "# Load training and validation sets\n",
    " (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
    "# Resize images to 244x244\n",
    " X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:,:,:,:][:3000]])\n",
    " X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:,:,:,:][:3000]])\n",
    " Y_train = Y_train[:3000]\n",
    " Y_valid = Y_valid[:3000]\n",
    "# Transform targets to keras compatible format\n",
    " Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    " Y_valid = np_utils.to_categorical(Y_valid, num_classes)\n",
    "\n",
    " X_train = X_train.astype('float32')\n",
    " X_valid = X_valid.astype('float32')\n",
    "# making all the values range between 0 and 1\n",
    " X_train = X_train / 255.0\n",
    " X_valid = X_valid / 255.0\n",
    " return X_train, Y_train, X_valid, Y_valid\n",
    "\n",
    "X_train, y_train, X_test, y_test = cifar10_data(224, 224)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-09-24T08:51:55.589069Z",
     "iopub.execute_input": "2023-09-24T08:51:55.589648Z",
     "iopub.status.idle": "2023-09-24T08:52:13.562758Z",
     "shell.execute_reply.started": "2023-09-24T08:51:55.589598Z",
     "shell.execute_reply": "2023-09-24T08:52:13.561740Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 8s 0us/step\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def inception_module(x,filters_1x1,filters_3x3_reduce,filters_3x3,\n",
    " filters_5x5_reduce,filters_5x5,filters_pool_proj,name=None):\n",
    "\n",
    " conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "\n",
    " conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    " conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)\n",
    " conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    " conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)\n",
    " pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    " pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n",
    " output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
    "\n",
    " return output\n",
    "\n",
    "kernel_init = keras.initializers.glorot_uniform()\n",
    "bias_init = keras.initializers.Constant(value=0.2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T08:52:13.564164Z",
     "iopub.execute_input": "2023-09-24T08:52:13.564486Z",
     "iopub.status.idle": "2023-09-24T08:52:13.574826Z",
     "shell.execute_reply.started": "2023-09-24T08:52:13.564436Z",
     "shell.execute_reply": "2023-09-24T08:52:13.573990Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_layer = Input(shape=(224, 224, 3))\n",
    "x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_layer)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
    "x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n",
    "x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
    "x = inception_module(x,filters_1x1=64,filters_3x3_reduce=96,\n",
    " filters_3x3=128,filters_5x5_reduce=16,\n",
    " filters_5x5=32,filters_pool_proj=32,\n",
    " name='inception_3a')\n",
    "x = inception_module(x,filters_1x1=128,filters_3x3_reduce=128,\n",
    " filters_3x3=192,filters_5x5_reduce=32,\n",
    " filters_5x5=96,filters_pool_proj=64,\n",
    " name='inception_3b')\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
    "x = inception_module(x,filters_1x1=192,filters_3x3_reduce=96,\n",
    "filters_3x3=208,filters_5x5_reduce=16,filters_5x5=48,filters_pool_proj=64,\n",
    " name='inception_4a')\n",
    "x1 = AveragePooling2D((5, 5), strides=3)(x)\n",
    "x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n",
    "x1 = Flatten()(x1)\n",
    "x1 = Dense(1024, activation='relu')(x1)\n",
    "x1 = Dropout(0.7)(x1)\n",
    "x1 = Dense(10, activation='softmax', name='auxilliary_output_1')(x1)\n",
    "x = inception_module(x,filters_1x1=160,filters_3x3_reduce=112,\n",
    "filters_3x3=224,filters_5x5_reduce=24,filters_5x5=64,filters_pool_proj=64,name='inception_4b')\n",
    "x = inception_module(x,filters_1x1=128,filters_3x3_reduce=128,\n",
    " filters_3x3=256,filters_5x5_reduce=24,filters_5x5=64,\n",
    " filters_pool_proj=64,name='inception_4c')\n",
    "x = inception_module(x,filters_1x1=112,filters_3x3_reduce=144,\n",
    " filters_3x3=288,filters_5x5_reduce=32,filters_5x5=64,\n",
    " filters_pool_proj=64,\n",
    " name='inception_4d')\n",
    "x2 = AveragePooling2D((5, 5), strides=3)(x)\n",
    "x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n",
    "x2 = Flatten()(x2)\n",
    "x2 = Dense(1024, activation='relu')(x2)\n",
    "x2 = Dropout(0.7)(x2)\n",
    "x2 = Dense(10, activation='softmax', name='auxilliary_output_2')(x2)\n",
    "x = inception_module(x,filters_1x1=256,filters_3x3_reduce=160,\n",
    " filters_3x3=320,filters_5x5_reduce=32,filters_5x5=128,\n",
    " filters_pool_proj=128,\n",
    " name='inception_4e')\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
    "x = inception_module(x,filters_1x1=256,filters_3x3_reduce=160,\n",
    " filters_3x3=320,filters_5x5_reduce=32,filters_5x5=128,\n",
    " filters_pool_proj=128,\n",
    " name='inception_5a')\n",
    "x = inception_module(x, filters_1x1=384,filters_3x3_reduce=192,\n",
    " filters_3x3=384,filters_5x5_reduce=48,filters_5x5=128,\n",
    " filters_pool_proj=128,\n",
    " name='inception_5b')\n",
    "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(10, activation='softmax', name='output')(x)\n",
    "model = Model(input_layer, [x, x1, x2], name='inception_v1')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T08:52:13.576266Z",
     "iopub.execute_input": "2023-09-24T08:52:13.576778Z",
     "iopub.status.idle": "2023-09-24T08:52:14.674238Z",
     "shell.execute_reply.started": "2023-09-24T08:52:13.576719Z",
     "shell.execute_reply": "2023-09-24T08:52:14.673521Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 20\n",
    "initial_lrate = 0.01\n",
    "def decay(epoch, steps=100):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.25\n",
    "    epochs_drop = 8\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "sgd = SGD(lr=initial_lrate, momentum=0.5, nesterov=False)\n",
    "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
    "model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy'], loss_weights=[1, 0.3, 0.3], optimizer=sgd, metrics=['accuracy'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T08:52:14.675761Z",
     "iopub.execute_input": "2023-09-24T08:52:14.676229Z",
     "iopub.status.idle": "2023-09-24T08:52:14.764686Z",
     "shell.execute_reply.started": "2023-09-24T08:52:14.676021Z",
     "shell.execute_reply": "2023-09-24T08:52:14.763927Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(X_train, [y_train, y_train, y_train],validation_data=(X_test, [y_test, y_test, y_test]), epochs=epochs, batch_size=256, callbacks=[lr_sc])"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-09-24T08:52:14.766142Z",
     "iopub.execute_input": "2023-09-24T08:52:14.766597Z",
     "iopub.status.idle": "2023-09-24T08:56:59.290036Z",
     "shell.execute_reply.started": "2023-09-24T08:52:14.766408Z",
     "shell.execute_reply": "2023-09-24T08:56:59.289187Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 3000 samples, validate on 3000 samples\nEpoch 1/20\n\nEpoch 00001: LearningRateScheduler setting learning rate to 0.01.\n3000/3000 [==============================] - 25s 8ms/step - loss: 3.9455 - output_loss: 2.4786 - auxilliary_output_1_loss: 2.4493 - auxilliary_output_2_loss: 2.4404 - output_acc: 0.0950 - auxilliary_output_1_acc: 0.0960 - auxilliary_output_2_acc: 0.1023 - val_loss: 3.6957 - val_output_loss: 2.3146 - val_auxilliary_output_1_loss: 2.3015 - val_auxilliary_output_2_loss: 2.3025 - val_output_acc: 0.1023 - val_auxilliary_output_1_acc: 0.1060 - val_auxilliary_output_2_acc: 0.1283\nEpoch 2/20\n\nEpoch 00002: LearningRateScheduler setting learning rate to 0.01.\n3000/3000 [==============================] - 14s 5ms/step - loss: 3.7904 - output_loss: 2.3820 - auxilliary_output_1_loss: 2.3488 - auxilliary_output_2_loss: 2.3460 - output_acc: 0.0890 - auxilliary_output_1_acc: 0.0947 - auxilliary_output_2_acc: 0.1047 - val_loss: 3.6900 - val_output_loss: 2.3080 - val_auxilliary_output_1_loss: 2.3013 - val_auxilliary_output_2_loss: 2.3052 - val_output_acc: 0.1060 - val_auxilliary_output_1_acc: 0.1060 - val_auxilliary_output_2_acc: 0.1060\nEpoch 3/20\n\nEpoch 00003: LearningRateScheduler setting learning rate to 0.01.\n3000/3000 [==============================] - 14s 5ms/step - loss: 3.7494 - output_loss: 2.3560 - auxilliary_output_1_loss: 2.3252 - auxilliary_output_2_loss: 2.3194 - output_acc: 0.1123 - auxilliary_output_1_acc: 0.1087 - auxilliary_output_2_acc: 0.1070 - val_loss: 3.6961 - val_output_loss: 2.3155 - val_auxilliary_output_1_loss: 2.2990 - val_auxilliary_output_2_loss: 2.3031 - val_output_acc: 0.1210 - val_auxilliary_output_1_acc: 0.1057 - val_auxilliary_output_2_acc: 0.1023\nEpoch 4/20\n\nEpoch 00004: LearningRateScheduler setting learning rate to 0.01.\n3000/3000 [==============================] - 14s 5ms/step - loss: 3.7420 - output_loss: 2.3510 - auxilliary_output_1_loss: 2.3147 - auxilliary_output_2_loss: 2.3221 - output_acc: 0.0997 - auxilliary_output_1_acc: 0.1033 - auxilliary_output_2_acc: 0.0930 - val_loss: 3.6850 - val_output_loss: 2.3057 - val_auxilliary_output_1_loss: 2.2975 - val_auxilliary_output_2_loss: 2.3001 - val_output_acc: 0.1060 - val_auxilliary_output_1_acc: 0.1083 - val_auxilliary_output_2_acc: 0.1617\nEpoch 5/20\n\nEpoch 00005: LearningRateScheduler setting learning rate to 0.01.\n3000/3000 [==============================] - 13s 4ms/step - loss: 3.7344 - output_loss: 2.3460 - auxilliary_output_1_loss: 2.3149 - auxilliary_output_2_loss: 2.3128 - output_acc: 0.0980 - auxilliary_output_1_acc: 0.0917 - auxilliary_output_2_acc: 0.0937 - val_loss: 3.6796 - val_output_loss: 2.3012 - val_auxilliary_output_1_loss: 2.2953 - val_auxilliary_output_2_loss: 2.2995 - val_output_acc: 0.1023 - val_auxilliary_output_1_acc: 0.1067 - val_auxilliary_output_2_acc: 0.1060\nEpoch 6/20\n\nEpoch 00006: LearningRateScheduler setting learning rate to 0.01.\n3000/3000 [==============================] - 14s 5ms/step - loss: 3.7255 - output_loss: 2.3419 - auxilliary_output_1_loss: 2.3025 - auxilliary_output_2_loss: 2.3092 - output_acc: 0.0910 - auxilliary_output_1_acc: 0.1130 - auxilliary_output_2_acc: 0.1030 - val_loss: 3.6857 - val_output_loss: 2.3078 - val_auxilliary_output_1_loss: 2.2934 - val_auxilliary_output_2_loss: 2.2995 - val_output_acc: 0.0983 - val_auxilliary_output_1_acc: 0.1517 - val_auxilliary_output_2_acc: 0.1060\nEpoch 7/20\n\nEpoch 00007: LearningRateScheduler setting learning rate to 0.01.\n3000/3000 [==============================] - 13s 4ms/step - loss: 3.7090 - output_loss: 2.3288 - auxilliary_output_1_loss: 2.2942 - auxilliary_output_2_loss: 2.3067 - output_acc: 0.1043 - auxilliary_output_1_acc: 0.1250 - auxilliary_output_2_acc: 0.1037 - val_loss: 3.6783 - val_output_loss: 2.3016 - val_auxilliary_output_1_loss: 2.2909 - val_auxilliary_output_2_loss: 2.2980 - val_output_acc: 0.1173 - val_auxilliary_output_1_acc: 0.1357 - val_auxilliary_output_2_acc: 0.1527\nEpoch 8/20\n\nEpoch 00008: LearningRateScheduler setting learning rate to 0.0025.\n3000/3000 [==============================] - 14s 5ms/step - loss: 3.7069 - output_loss: 2.3256 - auxilliary_output_1_loss: 2.3006 - auxilliary_output_2_loss: 2.3039 - output_acc: 0.0993 - auxilliary_output_1_acc: 0.1147 - auxilliary_output_2_acc: 0.1077 - val_loss: 3.6696 - val_output_loss: 2.2941 - val_auxilliary_output_1_loss: 2.2890 - val_auxilliary_output_2_loss: 2.2958 - val_output_acc: 0.1083 - val_auxilliary_output_1_acc: 0.1710 - val_auxilliary_output_2_acc: 0.1483\nEpoch 9/20\n\nEpoch 00009: LearningRateScheduler setting learning rate to 0.0025.\n3000/3000 [==============================] - 13s 4ms/step - loss: 3.7024 - output_loss: 2.3232 - auxilliary_output_1_loss: 2.2943 - auxilliary_output_2_loss: 2.3031 - output_acc: 0.1143 - auxilliary_output_1_acc: 0.1270 - auxilliary_output_2_acc: 0.1117 - val_loss: 3.6672 - val_output_loss: 2.2925 - val_auxilliary_output_1_loss: 2.2876 - val_auxilliary_output_2_loss: 2.2947 - val_output_acc: 0.1700 - val_auxilliary_output_1_acc: 0.1800 - val_auxilliary_output_2_acc: 0.1700\nEpoch 10/20\n\nEpoch 00010: LearningRateScheduler setting learning rate to 0.0025.\n3000/3000 [==============================] - 13s 4ms/step - loss: 3.7023 - output_loss: 2.3237 - auxilliary_output_1_loss: 2.2965 - auxilliary_output_2_loss: 2.2988 - output_acc: 0.1070 - auxilliary_output_1_acc: 0.1277 - auxilliary_output_2_acc: 0.1200 - val_loss: 3.6651 - val_output_loss: 2.2912 - val_auxilliary_output_1_loss: 2.2863 - val_auxilliary_output_2_loss: 2.2933 - val_output_acc: 0.1373 - val_auxilliary_output_1_acc: 0.1607 - val_auxilliary_output_2_acc: 0.1703\nEpoch 11/20\n\nEpoch 00011: LearningRateScheduler setting learning rate to 0.0025.\n3000/3000 [==============================] - 14s 5ms/step - loss: 3.6910 - output_loss: 2.3150 - auxilliary_output_1_loss: 2.2909 - auxilliary_output_2_loss: 2.2958 - output_acc: 0.1063 - auxilliary_output_1_acc: 0.1270 - auxilliary_output_2_acc: 0.1273 - val_loss: 3.6632 - val_output_loss: 2.2901 - val_auxilliary_output_1_loss: 2.2850 - val_auxilliary_output_2_loss: 2.2920 - val_output_acc: 0.1167 - val_auxilliary_output_1_acc: 0.1700 - val_auxilliary_output_2_acc: 0.1703\nEpoch 12/20\n\nEpoch 00012: LearningRateScheduler setting learning rate to 0.0025.\n3000/3000 [==============================] - 13s 4ms/step - loss: 3.6901 - output_loss: 2.3139 - auxilliary_output_1_loss: 2.2896 - auxilliary_output_2_loss: 2.2980 - output_acc: 0.1140 - auxilliary_output_1_acc: 0.1310 - auxilliary_output_2_acc: 0.1223 - val_loss: 3.6602 - val_output_loss: 2.2878 - val_auxilliary_output_1_loss: 2.2838 - val_auxilliary_output_2_loss: 2.2908 - val_output_acc: 0.1477 - val_auxilliary_output_1_acc: 0.1733 - val_auxilliary_output_2_acc: 0.1663\nEpoch 13/20\n\nEpoch 00013: LearningRateScheduler setting learning rate to 0.0025.\n3000/3000 [==============================] - 14s 5ms/step - loss: 3.6822 - output_loss: 2.3069 - auxilliary_output_1_loss: 2.2893 - auxilliary_output_2_loss: 2.2949 - output_acc: 0.1243 - auxilliary_output_1_acc: 0.1187 - auxilliary_output_2_acc: 0.1350 - val_loss: 3.6568 - val_output_loss: 2.2852 - val_auxilliary_output_1_loss: 2.2827 - val_auxilliary_output_2_loss: 2.2893 - val_output_acc: 0.2037 - val_auxilliary_output_1_acc: 0.1717 - val_auxilliary_output_2_acc: 0.1787\nEpoch 14/20\n\nEpoch 00014: LearningRateScheduler setting learning rate to 0.0025.\n3000/3000 [==============================] - 13s 4ms/step - loss: 3.6861 - output_loss: 2.3108 - auxilliary_output_1_loss: 2.2911 - auxilliary_output_2_loss: 2.2934 - output_acc: 0.1050 - auxilliary_output_1_acc: 0.1263 - auxilliary_output_2_acc: 0.1223 - val_loss: 3.6544 - val_output_loss: 2.2834 - val_auxilliary_output_1_loss: 2.2821 - val_auxilliary_output_2_loss: 2.2880 - val_output_acc: 0.1627 - val_auxilliary_output_1_acc: 0.1913 - val_auxilliary_output_2_acc: 0.1593\nEpoch 15/20\n\nEpoch 00015: LearningRateScheduler setting learning rate to 0.0025.\n3000/3000 [==============================] - 14s 5ms/step - loss: 3.6718 - output_loss: 2.2993 - auxilliary_output_1_loss: 2.2857 - auxilliary_output_2_loss: 2.2894 - output_acc: 0.1240 - auxilliary_output_1_acc: 0.1330 - auxilliary_output_2_acc: 0.1373 - val_loss: 3.6494 - val_output_loss: 2.2795 - val_auxilliary_output_1_loss: 2.2804 - val_auxilliary_output_2_loss: 2.2860 - val_output_acc: 0.1680 - val_auxilliary_output_1_acc: 0.1950 - val_auxilliary_output_2_acc: 0.1617\nEpoch 16/20\n\nEpoch 00016: LearningRateScheduler setting learning rate to 0.000625.\n3000/3000 [==============================] - 13s 4ms/step - loss: 3.6753 - output_loss: 2.3022 - auxilliary_output_1_loss: 2.2856 - auxilliary_output_2_loss: 2.2913 - output_acc: 0.1210 - auxilliary_output_1_acc: 0.1327 - auxilliary_output_2_acc: 0.1320 - val_loss: 3.6476 - val_output_loss: 2.2781 - val_auxilliary_output_1_loss: 2.2797 - val_auxilliary_output_2_loss: 2.2853 - val_output_acc: 0.2030 - val_auxilliary_output_1_acc: 0.1933 - val_auxilliary_output_2_acc: 0.1767\nEpoch 17/20\n\nEpoch 00017: LearningRateScheduler setting learning rate to 0.000625.\n3000/3000 [==============================] - 13s 4ms/step - loss: 3.6703 - output_loss: 2.2990 - auxilliary_output_1_loss: 2.2837 - auxilliary_output_2_loss: 2.2874 - output_acc: 0.1157 - auxilliary_output_1_acc: 0.1417 - auxilliary_output_2_acc: 0.1363 - val_loss: 3.6462 - val_output_loss: 2.2770 - val_auxilliary_output_1_loss: 2.2793 - val_auxilliary_output_2_loss: 2.2849 - val_output_acc: 0.2090 - val_auxilliary_output_1_acc: 0.1927 - val_auxilliary_output_2_acc: 0.1767\nEpoch 18/20\n\nEpoch 00018: LearningRateScheduler setting learning rate to 0.000625.\n3000/3000 [==============================] - 14s 5ms/step - loss: 3.6695 - output_loss: 2.2968 - auxilliary_output_1_loss: 2.2857 - auxilliary_output_2_loss: 2.2897 - output_acc: 0.1177 - auxilliary_output_1_acc: 0.1287 - auxilliary_output_2_acc: 0.1350 - val_loss: 3.6450 - val_output_loss: 2.2760 - val_auxilliary_output_1_loss: 2.2790 - val_auxilliary_output_2_loss: 2.2845 - val_output_acc: 0.1917 - val_auxilliary_output_1_acc: 0.1930 - val_auxilliary_output_2_acc: 0.1863\nEpoch 19/20\n\nEpoch 00019: LearningRateScheduler setting learning rate to 0.000625.\n3000/3000 [==============================] - 13s 4ms/step - loss: 3.6705 - output_loss: 2.2992 - auxilliary_output_1_loss: 2.2827 - auxilliary_output_2_loss: 2.2884 - output_acc: 0.1280 - auxilliary_output_1_acc: 0.1393 - auxilliary_output_2_acc: 0.1263 - val_loss: 3.6436 - val_output_loss: 2.2748 - val_auxilliary_output_1_loss: 2.2785 - val_auxilliary_output_2_loss: 2.2840 - val_output_acc: 0.1997 - val_auxilliary_output_1_acc: 0.1940 - val_auxilliary_output_2_acc: 0.1830\nEpoch 20/20\n\nEpoch 00020: LearningRateScheduler setting learning rate to 0.000625.\n3000/3000 [==============================] - 14s 5ms/step - loss: 3.6697 - output_loss: 2.2973 - auxilliary_output_1_loss: 2.2846 - auxilliary_output_2_loss: 2.2901 - output_acc: 0.1233 - auxilliary_output_1_acc: 0.1323 - auxilliary_output_2_acc: 0.1320 - val_loss: 3.6423 - val_output_loss: 2.2738 - val_auxilliary_output_1_loss: 2.2781 - val_auxilliary_output_2_loss: 2.2835 - val_output_acc: 0.1853 - val_auxilliary_output_1_acc: 0.1923 - val_auxilliary_output_2_acc: 0.1843\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}
